<!DOCTYPE html>
<html>

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Adrien Gruson</title>
	<link rel="stylesheet" href="https:&#x2F;&#x2F;beltegeuse.github.io&#x2F;research&#x2F;style.css?t=1581306696">

</head>

<body>
	<main class="content">
		<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
			<div class="container">
				<div class="d-none d-lg-inline-flex"><a class="navbar-brand" href="/">Adrien Gruson</a></div><button
					type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-content"
					aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
					<span><i class="fas fa-bars"></i></span></button>
				<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class="navbar-brand"
						href="/">Adrien Gruson</a></div>
				<div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">
					<ul class="navbar-nav d-md-inline-flex">
						<li class="nav-item"><a class="nav-link" href="/" data-target="#hero"><span>Home</span></a></li>
						<li class="nav-item"><a class="nav-link" href="/publication/" data-target="#featured"><span>Publications</span></a></li>
						<li class="nav-item"><a class="nav-link" href="/others" data-target="#projects"><span>Others</span></a></li>
					</ul>
				</div>
			</div>
		</nav>

		
<section id="publications">
		<div class="container">
			<div class="article-container">
				<h1>Temporal Coherency for Video Tone Mapping</h1>
				<span class="pub-authors">
						<p>R Boitard, K Bouatouch, R Cozot, D Thoreau, A Gruson</p>

				</div>
				<img src="/publication/temporal_video.png" class="pub-banner" itemprop="image">
				<p class="pub-abstract" itemprop="text">
					<h3 id="abstract">Abstract</h3>
<p>Tone Mapping Operators (TMOs) aim at converting real world high dynamic range (HDR) images captured with HDR cameras, into low dynamic range (LDR) images that can be displayed on LDR displays.  Several TMOs have been proposed over the last decade, from the simple global mapping to the more complex one simulating the human vision system.  While these solutions work generally well for still pictures, they are usually less effcient for video sequences as they are source of visual artifacts.  Only few of them can be adapted to cope with a sequence of images.  In this paper we present a major problem that a static TMO usually encounters while dealing with video sequences, namely the temporal coherency.  Indeed, as each tone mapper deals with each frame separately, no  temporal  coherency  is  taken  into  account  and  hence  the  results  can  be  quite  disturbing  for  high  varying dynamics in a video.  We propose a temporal coherency algorithm that is designed to analyze a video as a whole, and  from  its  characteristics  adapts  each  tone  mapped  frame  of  a  sequence  in  order  to  preserve  the  temporal coherency.  This temporal coherency algorithm has been tested on a set of real as well as Computer Graphics Image (CGI) content and put in competition with several algorithms that are designed to be time-dependent. Results show that temporal coherency preserves the overall contrast in a sequence of images.  Furthermore, this technique is applicable to any TMO as it is a post-processing that only depends on the used TMO.
				</p>
			</div>
		</div>
</section>

	</main>
</body>

</html>