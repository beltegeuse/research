<!DOCTYPE html>
<html>

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Adrien Gruson</title>
	<link rel="stylesheet" href="https:&#x2F;&#x2F;beltegeuse.github.io&#x2F;research&#x2F;style.css?t=1581949791">

</head>

<body>
	<main class="content">
		<div class="container">
			
		<nav class="navbar navbar-expand-lg navbar-light bg-light" id="navbar-main">
				<a class="navbar-brand" href="https:&#x2F;&#x2F;beltegeuse.github.io&#x2F;research">Adrien Gruson</a>
				
				<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-content" aria-controls="navbar-content" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				<div class="collapse navbar-collapse" id="navbar-content">
					<ul class="navbar-nav">
						<li class="nav-item"><a class="nav-link" href="https:&#x2F;&#x2F;beltegeuse.github.io&#x2F;research"
								data-target="#hero"><span>Home</span></a></li>
						<li class="nav-item"><a class="nav-link" href="https:&#x2F;&#x2F;beltegeuse.github.io&#x2F;research&#x2F;publication"
								data-target="#publications"><span>Publications</span></a></li>
						<li class="nav-item"><a class="nav-link" href="https:&#x2F;&#x2F;beltegeuse.github.io&#x2F;research&#x2F;others"
								data-target="#others"><span>Others</span></a></li>
					</ul>
				</div>
		</nav>
	</div>

		
<section id="publications">
		<div class="container">
			<div class="article-container">
				<h1>Scalable Virtual Ray Lights Rendering for Participating Media</h1>
				<span class="pub-authors">
						<p>N Vibert, A Gruson, H Stokholm, T Mortensen, W Jarosz, T Hachisuka, D Nowrouzezahrai</p>

				</div>
				<img src="https:&#x2F;&#x2F;beltegeuse.github.io&#x2F;research&#x2F;publication&#x2F;VRLLC.jpg" class="pub-banner" itemprop="image">
				<p class="pub-abstract" itemprop="text">
					<h3 id="abstract">Abstract</h3>
<p>Virtual ray lights (VRL) are a powerful representation for multiple-scattered light transport in volumetric participating media. While efficient Monte Carlo estimators can importance sample the contribution of a VRL along an entire sensor subpath, render time still scales linearly in the number of VRLs. We present a new scalable hierarchial VRL method that preferentially samples VRLs according to their image contribution. Similar to Lightcuts-based approaches, we derive a tight upper bound on the potential contribution of a VRL that is efficient to compute. Our bound takes into account the sampling probability densities used when estimating VRL contribution. Ours is the first such upper bound formulation, leading to an efficient and scalable rendering technique with only a few intuitive user parameters. We benchmark our approach in scenes with many VRLs, demonstrating improved scalability compared to existing state-of-the-art techniques
				</p>
			</div>
		</div>
</section>

	</main>
</body>

</html>