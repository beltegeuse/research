<!DOCTYPE html>
<html>

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Adrien Gruson</title>
	<link rel="stylesheet" href="https:&#x2F;&#x2F;beltegeuse.github.io&#x2F;research&#x2F;style.css?t=1581306696">

</head>

<body>
	<main class="content">
		<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
			<div class="container">
				<div class="d-none d-lg-inline-flex"><a class="navbar-brand" href="/">Adrien Gruson</a></div><button
					type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-content"
					aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
					<span><i class="fas fa-bars"></i></span></button>
				<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class="navbar-brand"
						href="/">Adrien Gruson</a></div>
				<div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">
					<ul class="navbar-nav d-md-inline-flex">
						<li class="nav-item"><a class="nav-link" href="/" data-target="#hero"><span>Home</span></a></li>
						<li class="nav-item"><a class="nav-link" href="/publication/" data-target="#featured"><span>Publications</span></a></li>
						<li class="nav-item"><a class="nav-link" href="/others" data-target="#projects"><span>Others</span></a></li>
					</ul>
				</div>
			</div>
		</nav>

		
<section id="publications">
		<div class="container">
			<div class="article-container">
				<h1>Scalable Virtual Ray Lights Rendering for Participating Media</h1>
				<span class="pub-authors">
						<p>N Vibert, A Gruson, H Stokholm, T Mortensen, W Jarosz, T Hachisuka, D Nowrouzezahrai</p>

				</div>
				<img src="/publication/VRLLC.jpg" class="pub-banner" itemprop="image">
				<p class="pub-abstract" itemprop="text">
					<h3 id="abstract">Abstract</h3>
<p>Virtual ray lights (VRL) are a powerful representation for multiple-scattered light transport in volumetric participating media. While efficient Monte Carlo estimators can importance sample the contribution of a VRL along an entire sensor subpath, render time still scales linearly in the number of VRLs. We present a new scalable hierarchial VRL method that preferentially samples VRLs according to their image contribution. Similar to Lightcuts-based approaches, we derive a tight upper bound on the potential contribution of a VRL that is efficient to compute. Our bound takes into account the sampling probability densities used when estimating VRL contribution. Ours is the first such upper bound formulation, leading to an efficient and scalable rendering technique with only a few intuitive user parameters. We benchmark our approach in scenes with many VRLs, demonstrating improved scalability compared to existing state-of-the-art techniques
				</p>
			</div>
		</div>
</section>

	</main>
</body>

</html>